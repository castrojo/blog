---
title: "Kubeflow 1.3 positioned to win software’s triple crown (Open source, Kubernetes, Machine Learning)"
layout: post
toc: true
comments: true
image: images/logo.png
hide: false
categories: [release]
permalink: /kubeflow-1.3-release/
author: "Josh Bottum, Thea Lamkin"
---

Like the elite colts and mares poised to win the Kentucky Derby, Kubeflow’s new 1.3 software release embodies a 3 year old community that is the odds-on favorite for software’s triple crown (Open Source, Kubernetes, Machine Learning).

Similar to the annual horse races, the yearly Kubeflow Community User Survey enables us to measure Kubeflow.  When compared to [last year’s survey](https://www.youtube.com/watch?v=4228OEenuGc), the [‘21 Survey](https://blog.kubeflow.org/kubeflow-continues-to-move-to-production) showed a 50% increase in responses and a whopping 300% increase in users supporting production deployments, which builds on Kubeflow’s lineage as a maturing thoroughbred.

The user survey responses, especially from ML engineers, architects and data scientists, are acting as Kubeflow’s jockeys and their input is guiding the Kubeflow contributors.   With Kubeflow 1.3, users are enjoying simplified ML workflows coupled with unparalleled Kubernetes’ operational and infrastructure efficiencies. Users are also cheering for the simplified GitOps-inspired installation patterns delivered by Kubeflow’s manifest re-organization and support for current Istio versions including v1.9.1.

## Streamlined ML workflows delivered via new UIs 

Data scientists are winning across the board with new and updated user interfaces (UIs) for KFServing, Katib, TensorBoard, Persistent Volumes, Pipelines and Kale.  These new UIs address many of the ML tasks that are time consuming and technically challenging.  The UIs reduce the need for a data scientist to dive down into the mud of kfctl or docker cli commands.   

**[Kubeflow User Survey Results](https://blog.kubeflow.org/kubeflow-continues-to-move-to-production#using-kubeflow-goes-beyond-just-training) - March ‘21**

![alt_text](images/2021-03-13-kubeflow-1.3/image1.png)

*   KFServing ([Video Tour](https://www.youtube.com/watch?v=L0cTPM4I8CU))
    *   The KFServing UI simplifies model serving and monitoring by providing easy access to your model’s operational status, configuration, metrics, and logging.  You can easily find information on your serving components i.e. predictor, transformer, and explainer, along with their details: framework, runtime, storage uri, namespace and yaml. (PR #[1328](https://github.com/kubeflow/kfserving/pull/1328))
*   Katib ([Video Tour](https://www.youtube.com/watch?v=VDINH5WkBhA))
    *   The Katib UI is integrated with the central dashboard and streamlines hyperparameter tuning by presenting a visualization graph and a table that compares each trial’s performance along with its hyperparameters.  You can also review the details of each trial’s algorithm, metrics collector and yaml. (PR [1](https://github.com/kubeflow/katib/projects/1))
*   TensorBoard ([Video tour](https://www.youtube.com/watch?v=eMDF2Bk8YRY))
    *   The TensorBoard UI streamlines the TensorBoard configuration tasks, especially for logging of training jobs which are running in Notebooks or Pipelines.  It simplifies accessibility to metrics, which helps you to improve model accuracy , identify performance bottlenecks, and reduce unproductive training jobs.  
*   Volume Manager ([Video tour](https://www.youtube.com/watch?v=jU2DtSWahdA))
    *   The Volume Manager enables you to manage your data and persistent volumes.  For the volumes in your namespace, it streamlines the creation and deletion of volumes, which then can be easily attached to your notebooks.  PR [5684](https://github.com/kubeflow/kubeflow/pull/5684) 
*   Kale ([Video tour](https://www.youtube.com/watch?v=ANBkUySirGg))
    *   The updated Kale UI, a JupyterLab extension, simplifies your hyperparameter tuning trial set-up.  The UI walks you through these steps: enter your hyperparameters as a list or a range, pick your search algorithm (Grid, Random, Bayesian) and the parameter to be optimized i.e. minimize loss.  Then with a click of a button, your Katib trials are set-up, snapshotted, tracked, and run.
*   Kubeflow Pipelines (KFP)
    *   The KFP UI has been reorganized for a more unified experience (PR [4925](https://github.com/kubeflow/pipelines/pull/4925)), and includes the ability to manage recurring runs via new “JobsList” and “AllJobslist” pages (PR [5131](https://github.com/kubeflow/pipelines/pull/5131)) and simplified view of dependency graphs.

Beyond the UIs, data scientists will also enjoy the enhancements to Notebooks and KFServing. In addition to the aforementioned integration with TensorBoard, the Notebook contributors have provided updated example images for ML frameworks and development environments:

*   Tensorflow 2.0 and PyTorch
*   VS Code and RStudio

KFServing enhancements include simplified canary rollouts with traffic splitting at the Knative revisions level. It also delivers extended ML framework support for:

*   TorchServe predict and PyTorch Captum explain 
*   PMMLServer, PR [1141](https://github.com/kubeflow/kfserving/pull/1141)
*   LightGBM \

## Infrastructure and Operational Efficiencies

ML engineers have won a trifecta with 1.3’s delivery of operational and infrastructure efficiencies, which are coupled with streamlined installation patterns and upgraded Istio version support.  The following chart provides a summary of the top features in 1.3.  


<table>
  <tr>
   <td><strong>Feature</strong>
   </td>
   <td><strong>Benefits</strong>
   </td>
  </tr>
  <tr>
   <td><a href="https://github.com/yuzliu/kfserving/blob/master/docs/MULTIMODELSERVING_GUIDE.md">Multi-model serving</a> 
   </td>
   <td>More models on same infra and workaround cluster limits        i.e. # of pods & ip addresses
   </td>
  </tr>
  <tr>
   <td>Pod affinity
   </td>
   <td>Avoid unnecessary usage on GPU or large CPU nodes
   </td>
  </tr>
  <tr>
   <td>gRPC support 
   </td>
   <td>Fewer messages, less bandwidth for KFServing workloads
   </td>
  </tr>
  <tr>
   <td>Katib trial templates
   </td>
   <td>Simplifies hyperparameter tuning set-up for custom model types
   </td>
  </tr>
  <tr>
   <td>Katib early stopping
   </td>
   <td>Stops hyperparameter tuning trials that are unproductive 
   </td>
  </tr>
  <tr>
   <td>Pipelines step caching
   </td>
   <td>Re-use results from previously run steps
   </td>
  </tr>
  <tr>
   <td>Multi-user pipelines
   </td>
   <td>User and resource isolation for non-GCP environments.
   </td>
  </tr>
  <tr>
   <td>Manifests refactoring
   </td>
   <td>Simplifies Kubeflow installation and upgrades
   </td>
  </tr>
  <tr>
   <td>Istio upgradability
   </td>
   <td>Improved security, day 2 operations, compatibility and support
   </td>
  </tr>
</table>

We are pleased to announce that the user documentation on Kubeflow.org has also been updated (PR [2546](https://github.com/kubeflow/website/issues/2546)).   Additional detailed documentation, especially on the valuable working group deliveries, can be found here:

*   Kubeflow Pipeline 1.3 Project (PR [12](https://github.com/kubeflow/pipelines/projects/12))
*   [Kubeflow Pipelines SDK with Tekton](https://www.kubeflow.org/docs/components/pipelines/sdk/pipelines-with-tekton/) 
*   [Operationalize, scale and infuse trust in AI models using KFServing](https://blog.kubeflow.org/release/official/2021/03/08/kfserving-0.5.html)
*   [Kubeflow Katib: Scalable, portable and cloud native system for AutoML](https://blog.kubeflow.org/katib/)

## Streamlined Installation

ML Engineers, who are installing Kubeflow, have a clear path to victory as Kubeflow 1.3 includes new manifests and upgraded Istio support.  For more information on installation patterns for each distribution, please visit the [Getting Started](https://www.kubeflow.org/docs/started/) page on Kubeflow.org.  If you are supporting a distribution or just interested in low-level details, please review the Kubeflow Installation Guide (PR XX).  

## Saddle up and take Kubeflow 1.3 for a ride!

Kubeflow 1.3 new features are easy to try on these tutorials:

*   Open Vaccine [Tutorial](https://codelabs.arrikto.com/codelabs/minikf-kale-katib-kfserving/index.html#0)
    *   Use the new UIs to build an ML Pipeline, tune your model, and then deploy and monitor it.   This tensorflow-based example was modified from a Kaggle tutorial for building a Covid 19 vaccine from bases in an mRNA molecule.  The tutorial is easy to run on AWS and GCP in about 1 hour.
*   Model Risk Management Tutorial
    *   This model produces SR11-7 compliance reports for financial institutions.  The example provides reporting on bias in a home mortgage lending model.  The tutorial is easy to run on AWS and GCP in about 1 hour.
*   Tutorial 3

## Voices from the Community

The Kubeflow Community’s ‘21 [User Survey](https://blog.kubeflow.org/kubeflow-continues-to-move-to-production) provides the contributors with great insights, especially on where to focus our attention:

![alt_text](images/2021-03-13-kubeflow-1.3/image2.png)

With new documentation, installation and tutorials, Kubeflow is breaking away from the field and helping your ML Platform to land in the winner’s circle.  Kubeflow has fans from around the world and here are a few of their cheers:  

Multi-model serving improves scalability and helps overcome pod per cluster limitations.  TBD

gRPC for model serving calls saves us bandwidth. TBD

Stopping and restarting notebooks enables us to protect our work and save infrastructure costs. TBD,

Early stopping prevents us from overfitting models and stop unproductive hyperparameter tuning trials, TBD

The addition of VS Code and RStudio as IDE options, alongside Jupyter Notebooks, positions Kubeflow for greater adoption. With Notebooks and KFServing supporting Pod Affinity, engineers will have greater control with placing workloads in large clusters where GPUs are not on every node.  TBD

Pipeline Step caching checks if a step has been run, and uses the existing results rather than running the pipeline step again, which saves time and infrastructure.   TBD

The TensorBoard UI improves model training by making it easy to visualize important metrics, find bottlenecks, and reduce unproductive training jobs.   TBD

## Join the Community

We would like to thank everyone for their efforts on Kubeflow 1.3, especially the code contributors and working group leads. As you can see from the extensive contributions to Kubeflow 1.3, the Kubeflow Community is vibrant and diverse, and solving real world problems for organizations around the world. 

Want to help? The Kubeflow Community [Working Groups](https://github.com/kubeflow/community/blob/master/wg-list.md) hold open meetings, public lists, and are always looking for more volunteers and users to unlock the potential of machine learning. If you’re interested in becoming a Kubeflow contributor, please feel free to check out the resources below, we look forward to working with you!

*   Visit our[ Kubeflow website](https://www.kubeflow.org/) or[ Kubeflow GitHub Page](https://github.com/kubeflow)
*   Join the[ Kubeflow Slack channel](https://join.slack.com/t/kubeflow/shared_invite/enQtMjgyMzMxNDgyMTQ5LWUwMTIxNmZlZTk2NGU0MmFiNDE4YWJiMzFiOGNkZGZjZmRlNTExNmUwMmQ2NzMwYzk5YzQxOWQyODBlZGY2OTg)
*   Join the[ kubeflow-discuss](https://groups.google.com/forum/#!forum/kubeflow-discuss) mailing list
*   Attend a[ weekly community meeting](https://www.kubeflow.org/docs/about/community/)